{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "derived-fifteen",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/emilyolafson/GIT/ENIGMA/enigma_disconnections/results/fs86subj_normed_motor_scores_chacovol_chronic_ridge_crossval1_lesionload_0_scores.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b5f87baec0b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnperms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                         \u001b[0;31m#print(filename +'_'+ str(k) + '_scores.npy')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                         \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_scores.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                         \u001b[0mcorrelation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_correlations.npy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;34m'_scores.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/myenv/lib/python3.9/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/emilyolafson/GIT/ENIGMA/enigma_disconnections/results/fs86subj_normed_motor_scores_chacovol_chronic_ridge_crossval1_lesionload_0_scores.npy'"
     ]
    }
   ],
   "source": [
    "# check out models\n",
    "from cgi import test\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RepeatedKFold,ShuffleSplit, GroupKFold, LeaveOneGroupOut, train_test_split, GridSearchCV, cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.linear_model import Ridge\n",
    "import scipy.io as sio\n",
    "\n",
    "y_var = 'normed_motor_scores'\n",
    "chaco_type = 'chacovol'\n",
    "subset = 'chronic'\n",
    "models_tested = ['ridge']\n",
    "crossval ='2'\n",
    "results_path = '/Users/emilyolafson/GIT/ENIGMA/enigma_disconnections/results' \n",
    "mdl_label = models_tested[0]\n",
    "\n",
    "\n",
    "atlases = [ 'shen268']\n",
    "chaco_types = ['chacovol']\n",
    "crossval_types =['1', '5']\n",
    "nperms = 25\n",
    "nperms_null=30\n",
    "\n",
    "for atlas in atlases:\n",
    "        for chaco_type in chaco_types:\n",
    "            for crossval in crossval_types:\n",
    "                filename = results_path + '/{}_{}_{}_{}_{}_crossval{}'.format(atlas, y_var, chaco_type, subset, mdl_label,crossval)\n",
    "              \n",
    "                if crossval == '2':\n",
    "                    \n",
    "                    print('two -  Outer CV: Leave-one-site-out')\n",
    "                    print(correlation[0].shape)\n",
    "                    print(scores.shape)\n",
    "                    np.savetxt(filename + '_scores.txt', scores[0], delimiter = ',')\n",
    "                    for val in correlation[0]:\n",
    "                        newfile.append(val[0])\n",
    "                    np.savetxt(filename + '_correlation.txt', newfile, delimiter = ',')                   \n",
    "                if crossval == '3':\n",
    "                    print('three - Outer CV: Group K-fold')\n",
    "                    np.savetxt(filename + '_scores.txt', scores[0], delimiter = ',')\n",
    "                    for val in correlation[0]:\n",
    "                        newfile.append(val[0])\n",
    "                    np.savetxt(filename + '_correlation.txt', newfile, delimiter = ',')\n",
    "                    print(tmp[0])\n",
    "                if crossval == '4':\n",
    "                    print('four - Shuffle')\n",
    "                    np.savetxt(filename + '_scores.txt', scores[0], delimiter = ',')\n",
    "                    for val in correlation[0]:\n",
    "                        newfile.append(val[0])\n",
    "                    np.savetxt(filename + '_correlation.txt', newfile, delimiter = ',')\n",
    "                if (crossval == '5') | (crossval=='1'):\n",
    "                    counter =0\n",
    "                    for k in range(0, nperms):\n",
    "                        #print(filename +'_'+ str(k) + '_scores.npy')\n",
    "                        scores=np.load(filename +'_'+ str(k) + '_scores.npy',allow_pickle=True)\n",
    "                        correlation = np.load(filename +'_'+ str(k) +'_correlations.npy',allow_pickle=True)\n",
    "                        np.savetxt(filename +'_'+ str(k) +  '_scores.txt', scores[0], delimiter = ',')\n",
    "                        newfile=[]\n",
    "                        for val in correlation[0]:\n",
    "                            newfile.append(val[0])\n",
    "                        np.savetxt(filename +'_'+ str(k) +  '_correlations.txt', newfile, delimiter = ',')\n",
    "                        varimpts=np.load(filename +'_'+ str(k) + '_activation_weights.npy',allow_pickle=True)\n",
    "\n",
    "                        #print('----')\n",
    "                        varimpts=varimpts[counter:counter+5,:]\n",
    "                        print(filename +'_'+ str(k) + '_variable_impts.txt')\n",
    "                        print(varimpts.shape)\n",
    "                        sio.savemat(filename +'_'+ str(k) + '_activation_weights.mat', {'varimpts': varimpts})\n",
    "\n",
    "                       # np.savetxt(filename +'_'+ str(k) + '_activation_weights.txt',varimpts,delimiter = ',')\n",
    "                        mdl=np.load(filename +'_'+ str(k) + '_model.npy',allow_pickle=True)\n",
    "                        alphas=[]\n",
    "                        feats=[]\n",
    "                        #print(mdl[0][0]['featselect'])\n",
    "                        for a in range(0,5):\n",
    "                            alphas.append(mdl[0][a]['ridge'].alpha)\n",
    "                            feats.append(mdl[0][a]['featselect'].k)\n",
    "                            \n",
    "                        np.savetxt(filename +'_'+ str(k) +  '_alphas.txt', alphas, delimiter = ',')\n",
    "                        np.savetxt(filename +'_'+ str(k) +  '_feats.txt', feats, delimiter = ',')\n",
    "                        counter=counter+5\n",
    "\n",
    "                        \n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "canadian-dialogue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lesion load of all CST components\n",
    "atlases = [ 'fs86subj', 'shen268']\n",
    "chaco_types = ['chacovol']\n",
    "crossval_types =['1', '5']\n",
    "nperms = 25\n",
    "nperms_null=30\n",
    "\n",
    "for atlas in atlases:\n",
    "        for chaco_type in chaco_types:\n",
    "            for crossval in crossval_types:\n",
    "                filename = results_path + '/{}_{}_{}_{}_{}_crossval{}'.format(atlas, y_var, chaco_type, subset, mdl_label,crossval)\n",
    "              \n",
    "                if crossval == '2':\n",
    "                    \n",
    "                    print('two -  Outer CV: Leave-one-site-out')\n",
    "                    print(correlation[0].shape)\n",
    "                    print(scores.shape)\n",
    "                    np.savetxt(filename + '_scores.txt', scores[0], delimiter = ',')\n",
    "                    for val in correlation[0]:\n",
    "                        newfile.append(val[0])\n",
    "                    np.savetxt(filename + '_correlation.txt', newfile, delimiter = ',')                   \n",
    "                if crossval == '3':\n",
    "                    print('three - Outer CV: Group K-fold')\n",
    "                    np.savetxt(filename + '_scores.txt', scores[0], delimiter = ',')\n",
    "                    for val in correlation[0]:\n",
    "                        newfile.append(val[0])\n",
    "                    np.savetxt(filename + '_correlation.txt', newfile, delimiter = ',')\n",
    "                    print(tmp[0])\n",
    "                if crossval == '4':\n",
    "                    print('four - Shuffle')\n",
    "                    np.savetxt(filename + '_scores.txt', scores[0], delimiter = ',')\n",
    "                    for val in correlation[0]:\n",
    "                        newfile.append(val[0])\n",
    "                    np.savetxt(filename + '_correlation.txt', newfile, delimiter = ',')\n",
    "                if (crossval == '5') | (crossval=='1'):\n",
    "                    counter =0\n",
    "                    for k in range(1, nperms):\n",
    "                        #print(filename +'_'+ str(k) + '_scores.npy')\n",
    "                        scores=np.load(filename +'_'+ str(k) + '_lesionload_scores.npy',allow_pickle=True)\n",
    "                        correlation = np.load(filename +'_'+ str(k) +'_lesionload_correlations.npy',allow_pickle=True)\n",
    "                        np.savetxt(filename +'_'+ str(k) +  '_lesionload_scores.txt', scores[0], delimiter = ',')\n",
    "                        newfile=[]\n",
    "                        for val in correlation[0]:\n",
    "                            newfile.append(val[0])\n",
    "                        np.savetxt(filename +'_'+ str(k) +  '_lesionload_correlations.txt', newfile, delimiter = ',')\n",
    "                        #varimpts=np.load(filename +'_'+ str(k) + '_lesionload_activation_weights.npy',allow_pickle=True)\n",
    "\n",
    "                        #print('----')\n",
    "                        #varimpts=varimpts[counter:counter+5,:]\n",
    "                        #print(filename +'_'+ str(k) + '_variable_impts.txt')\n",
    "                        #print(varimpts.shape)\n",
    "                        #sio.savemat(filename +'_'+ str(k) + '_activation_weights.mat', {'varimpts': varimpts})\n",
    "\n",
    "                       # np.savetxt(filename +'_'+ str(k) + '_activation_weights.txt',varimpts,delimiter = ',')\n",
    "                        #mdl=np.load(filename +'_'+ str(k) + '_model.npy',allow_pickle=True)\n",
    "                        #alphas=[]\n",
    "                        #feats=[]\n",
    "                        #print(mdl[0][0]['featselect'])\n",
    "                        ##for a in range(0,5):\n",
    "                         #   alphas.append(mdl[0][a]['ridge'].alpha)\n",
    "                         #   feats.append(mdl[0][a]['featselect'].k)\n",
    "                            \n",
    "                        #np.savetxt(filename +'_'+ str(k) +  '_alphas.txt', alphas, delimiter = ',')\n",
    "                        #np.savetxt(filename +'_'+ str(k) +  '_feats.txt', feats, delimiter = ',')\n",
    "                        #counter=counter+5\n",
    "                        \n",
    "                     #   fs86subj_normed_motor_scores_chacovol_chronic_ridge_crossval1_1_lesionload_scores.npy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "running-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lesion load of CST only\n",
    "atlases = [ 'fs86subj', 'shen268']\n",
    "chaco_types = ['chacovol']\n",
    "crossval_types =['1', '5']\n",
    "mdl_label = 'ensemble_reg'\n",
    "nperms = 25\n",
    "nperms_null=30\n",
    "\n",
    "for atlas in atlases:\n",
    "        for chaco_type in chaco_types:\n",
    "            for crossval in crossval_types:\n",
    "                filename = results_path + '/{}_{}_{}_{}_{}_crossval{}'.format(atlas, y_var, chaco_type, subset, mdl_label,crossval)\n",
    "              \n",
    "                if crossval == '2':\n",
    "                    \n",
    "                    print('two -  Outer CV: Leave-one-site-out')\n",
    "                    print(correlation[0].shape)\n",
    "                    print(scores.shape)\n",
    "                    np.savetxt(filename + '_scores.txt', scores[0], delimiter = ',')\n",
    "                    for val in correlation[0]:\n",
    "                        newfile.append(val[0])\n",
    "                    np.savetxt(filename + '_correlation.txt', newfile, delimiter = ',')                   \n",
    "                if crossval == '3':\n",
    "                    print('three - Outer CV: Group K-fold')\n",
    "                    np.savetxt(filename + '_scores.txt', scores[0], delimiter = ',')\n",
    "                    for val in correlation[0]:\n",
    "                        newfile.append(val[0])\n",
    "                    np.savetxt(filename + '_correlation.txt', newfile, delimiter = ',')\n",
    "                    print(tmp[0])\n",
    "                if crossval == '4':\n",
    "                    print('four - Shuffle')\n",
    "                    np.savetxt(filename + '_scores.txt', scores[0], delimiter = ',')\n",
    "                    for val in correlation[0]:\n",
    "                        newfile.append(val[0])\n",
    "                    np.savetxt(filename + '_correlation.txt', newfile, delimiter = ',')\n",
    "                if (crossval == '5') | (crossval=='1'):\n",
    "                    counter =0\n",
    "                    for k in range(1, nperms):\n",
    "                        #print(filename +'_'+ str(k) + '_scores.npy')\n",
    "                        scores=np.load(filename +'_'+ str(k) + '_lesionload_cst_scores.npy',allow_pickle=True)\n",
    "                        correlation = np.load(filename +'_'+ str(k) +'_lesionload_cst_correlations.npy',allow_pickle=True)\n",
    "                        np.savetxt(filename +'_'+ str(k) +  '_lesionload_cst_scores.txt', scores[0], delimiter = ',')\n",
    "                        newfile=[]\n",
    "                        for val in correlation[0]:\n",
    "                            newfile.append(val[0])\n",
    "                        np.savetxt(filename +'_'+ str(k) +  '_lesionload_cst_correlations.txt', newfile, delimiter = ',')\n",
    "                        #varimpts=np.load(filename +'_'+ str(k) + '_lesionload_activation_weights.npy',allow_pickle=True)\n",
    "\n",
    "                        #print('----')\n",
    "                        #varimpts=varimpts[counter:counter+5,:]\n",
    "                        #print(filename +'_'+ str(k) + '_variable_impts.txt')\n",
    "                        #print(varimpts.shape)\n",
    "                        #sio.savemat(filename +'_'+ str(k) + '_activation_weights.mat', {'varimpts': varimpts})\n",
    "\n",
    "                       # np.savetxt(filename +'_'+ str(k) + '_activation_weights.txt',varimpts,delimiter = ',')\n",
    "                        #mdl=np.load(filename +'_'+ str(k) + '_model.npy',allow_pickle=True)\n",
    "                        #alphas=[]\n",
    "                        #feats=[]\n",
    "                        #print(mdl[0][0]['featselect'])\n",
    "                        ##for a in range(0,5):\n",
    "                         #   alphas.append(mdl[0][a]['ridge'].alpha)\n",
    "                         #   feats.append(mdl[0][a]['featselect'].k)\n",
    "                            \n",
    "                        #np.savetxt(filename +'_'+ str(k) +  '_alphas.txt', alphas, delimiter = ',')\n",
    "                        #np.savetxt(filename +'_'+ str(k) +  '_feats.txt', feats, delimiter = ',')\n",
    "                        #counter=counter+5\n",
    "                        \n",
    "                     #   fs86subj_normed_motor_scores_chacovol_chronic_ridge_crossval1_1_lesionload_scores.npy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "respective-sherman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35.\n",
      " 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50. 51. 52. 53.\n",
      " 54. 55. 56. 57. 58. 59. 60. 61. 62. 63. 64. 65. 66. 67. 68. 69. 70. 71.\n",
      " 72. 73. 74. 75. 76. 77. 78. 79. 80. 81. 82. 83. 84. 85. 86. 87. 88. 89.\n",
      " 90. 91. 92. 93. 94. 95. 96. 97. 98. 99.]\n",
      "[0. 1. 2. 3. 4.]\n",
      "[5. 6. 7. 8. 9.]\n",
      "[10. 11. 12. 13. 14.]\n",
      "[15. 16. 17. 18. 19.]\n",
      "[20. 21. 22. 23. 24.]\n",
      "[25. 26. 27. 28. 29.]\n",
      "[30. 31. 32. 33. 34.]\n",
      "[35. 36. 37. 38. 39.]\n",
      "[40. 41. 42. 43. 44.]\n",
      "[45. 46. 47. 48. 49.]\n",
      "[50. 51. 52. 53. 54.]\n",
      "[55. 56. 57. 58. 59.]\n",
      "[60. 61. 62. 63. 64.]\n",
      "[65. 66. 67. 68. 69.]\n",
      "[70. 71. 72. 73. 74.]\n",
      "[75. 76. 77. 78. 79.]\n",
      "[80. 81. 82. 83. 84.]\n",
      "[85. 86. 87. 88. 89.]\n",
      "[90. 91. 92. 93. 94.]\n",
      "[95. 96. 97. 98. 99.]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "shen268_normed_motor_scores_chacovol_chronic_ensemble_reg_crossval1_1_lesionload_cst_scores.npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8657ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble models\n",
    "atlases = [ 'fs86subj', 'shen268']\n",
    "chaco_types = ['chacovol']\n",
    "crossval_types =['1', '5']\n",
    "mdl_label = 'ridge'\n",
    "nperms = 25\n",
    "nperms_null=30\n",
    "\n",
    "for atlas in atlases:\n",
    "        for chaco_type in chaco_types:\n",
    "            for crossval in crossval_types:\n",
    "                filename = results_path + '/{}_{}_{}_{}_{}_crossval{}'.format(atlas, y_var, chaco_type, subset, mdl_label,crossval)\n",
    "              \n",
    "                if crossval == '2':\n",
    "                    \n",
    "                    print('two -  Outer CV: Leave-one-site-out')\n",
    "                    print(correlation[0].shape)\n",
    "                    print(scores.shape)\n",
    "                    np.savetxt(filename + '_scores.txt', scores[0], delimiter = ',')\n",
    "                    for val in correlation[0]:\n",
    "                        newfile.append(val[0])\n",
    "                    np.savetxt(filename + '_correlation.txt', newfile, delimiter = ',')                   \n",
    "                if crossval == '3':\n",
    "                    print('three - Outer CV: Group K-fold')\n",
    "                    np.savetxt(filename + '_scores.txt', scores[0], delimiter = ',')\n",
    "                    for val in correlation[0]:\n",
    "                        newfile.append(val[0])\n",
    "                    np.savetxt(filename + '_correlation.txt', newfile, delimiter = ',')\n",
    "                    print(tmp[0])\n",
    "                if crossval == '4':\n",
    "                    print('four - Shuffle')\n",
    "                    np.savetxt(filename + '_scores.txt', scores[0], delimiter = ',')\n",
    "                    for val in correlation[0]:\n",
    "                        newfile.append(val[0])\n",
    "                    np.savetxt(filename + '_correlation.txt', newfile, delimiter = ',')\n",
    "                if (crossval == '5') | (crossval=='1'):\n",
    "                    counter =0\n",
    "                    for k in range(1, nperms):\n",
    "                        #print(filename +'_'+ str(k) + '_scores.npy')\n",
    "                        #scores=np.load(filename +'_'+ str(k) + '_ensemble_scores_ensemble.npy',allow_pickle=True)\n",
    "                        correlation = np.load(filename +'_'+ str(k) +'_ensemble_correlations_ensemble.npy',allow_pickle=True)\n",
    "                       # np.savetxt(filename +'_'+ str(k) +  '_ensemble_scores_ensemble.txt', scores[0], delimiter = ',')\n",
    "                        newfile=[]\n",
    "                        for val in correlation[0]:\n",
    "                            newfile.append(val[0])\n",
    "                        np.savetxt(filename +'_'+ str(k) +  '_ensemble_correlations_ensemble.txt', newfile, delimiter = ',')\n",
    "                        #varimpts=np.load(filename +'_'+ str(k) + '_lesionload_activation_weights.npy',allow_pickle=True)\n",
    "\n",
    "                        #print('----')\n",
    "                        #varimpts=varimpts[counter:counter+5,:]\n",
    "                        #print(filename +'_'+ str(k) + '_variable_impts.txt')\n",
    "                        #print(varimpts.shape)\n",
    "                        #sio.savemat(filename +'_'+ str(k) + '_activation_weights.mat', {'varimpts': varimpts})\n",
    "\n",
    "                       # np.savetxt(filename +'_'+ str(k) + '_activation_weights.txt',varimpts,delimiter = ',')\n",
    "                        #mdl=np.load(filename +'_'+ str(k) + '_model.npy',allow_pickle=True)\n",
    "                        #alphas=[]\n",
    "                        #feats=[]\n",
    "                        #print(mdl[0][0]['featselect'])\n",
    "                        ##for a in range(0,5):\n",
    "                         #   alphas.append(mdl[0][a]['ridge'].alpha)\n",
    "                         #   feats.append(mdl[0][a]['featselect'].k)\n",
    "                            \n",
    "                        #np.savetxt(filename +'_'+ str(k) +  '_alphas.txt', alphas, delimiter = ',')\n",
    "                        #np.savetxt(filename +'_'+ str(k) +  '_feats.txt', feats, delimiter = ',')\n",
    "                        #counter=counter+5\n",
    "                        \n",
    "                     #   fs86subj_normed_motor_scores_chacovol_chronic_ridge_crossval1_1_lesionload_scores.npy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-cambridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "shen268_normed_motor_scores_chacovol_chronic_ridge_crossval5_9_ensemble_correlations_ensemble.npy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "43d17ee6803eb3ad2d3e1d5dbc5a33b5df735f96b5206a5a478194b252558b80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
